% !TeX encoding = UTF-8 Unicode

\documentclass[english,10pt]{article} % default 10pt

\usepackage{babel}
\usepackage{csquotes}
\MakeOuterQuote{"}

\usepackage{fontspec}
\setmonofont[Scale=0.95]{Courier 10 Pitch}



% STANDARD PACKAGES

\usepackage{geometry}
\geometry{a4paper}
\geometry{top=4cm,left=3cm,right=3cm,bottom=3.5cm}

\usepackage{graphicx}

\usepackage[parfill]{parskip}

\usepackage{booktabs} % better looking tables
\usepackage{tabu} % better looking tables

\usepackage{array} % better arrays/matrices in maths

\usepackage{verbatim}

\usepackage{subfig}

\usepackage[bookmarks,hidelinks]{hyperref}

\usepackage[x11names, svgnames]{xcolor}

\usepackage{enumerate}

\usepackage{cleveref}

\usepackage{microtype}

\RequirePackage[l2tabu, orthodox]{nag}

%\usepackage{ulem} % \emph becomes underlined (OK??)

\usepackage[labelfont=bf,labelsep=period]{caption}

\usepackage{syntax}

\usepackage{bussproofs}

\usepackage{drawstack}



% BIBLIOGRAPHY

\usepackage{natbib}



% LAYOUT

\usepackage{fancyhdr} % AFTER setting up page geometry
\pagestyle{fancy} % empty/plain/fancy
\renewcommand{\headrulewidth}{0pt}
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

\usepackage{titlesec}
\titleformat*{\section}{\Large\bfseries\sffamily}
\titleformat*{\subsection}{\large\bfseries\sffamily}
\titleformat*{\subsubsection}{\bfseries\sffamily}

\usepackage{titletoc}



% HELPFUL THINGS

\usepackage[framemethod=tikz]{mdframed}

\usepackage{tikz}
\usetikzlibrary{calc}
\usepackage{tikz-qtree,tikz-qtree-compat}
\usetikzlibrary{matrix,automata,positioning}

\tikzset{
  mdframeleftlinetitle/.style={
      rectangle,
      fill=white,
      scale=1,
      rotate=90,
      overlay}
}

\newmdenv[
  nobreak=true,
  linewidth=1.5pt,
  linecolor=black,
  fontcolor=black,
  hidealllines=true,
  leftline=true,
  skipabove=\baselineskip,
  skipbelow=\baselineskip,
  leftmargin=-10pt,
  splittopskip=0pt,
  innertopmargin=0pt,
  innerrightmargin=0pt,
  innerbottommargin=0pt,
  frametitleaboveskip=0pt,
  frametitlebelowskip=0pt
]{Warning}
% http://tex.stackexchange.com/questions/52023/mdframed-put-something-on-the-start-of-one-vertical-left-rule

\usepackage{minted}
\usemintedstyle{bw}




% MATHS

\usepackage{amsmath,amsfonts,amssymb,amsopn,amsthm}
\usepackage{mathtools}

%\usepackage[cmtip,all]{xy}
%\newcommand{\longsquiggly}{\!\xymatrix@C=1.6em{{}\ar@{~>}[r]&{}}\!}
%
%\usepackage{xytree}

\newtheoremstyle{definitionstyle}% name
  {1.5\parskip}%Space above
  {}%Space below
  {}%Body font
  {0pt}%Indent amount
  {\bfseries}% Theorem head font
  {.}%Punctuation after theorem head
  {5pt}%Space after theorem head 2
  {}%Theorem head spec (empty = ‘normal’)

\theoremstyle{definitionstyle}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}[definition]{Example}

\newtheoremstyle{lemmastyle}% name
  {1.5\parskip}%Space above
  {}%Space below
  {\itshape}%Body font
  {0pt}%Indent amount
  {\bfseries}% Theorem head font
  {.}%Punctuation after theorem head
  {5pt}%Space after theorem head 2
  {}%Theorem head spec (can be left empty, meaning ‘normal’)

\theoremstyle{lemmastyle}
\newtheorem{lem}[definition]{Lemma}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{thm}[definition]{Theorem}

% renewing the proof environment to correct the above spacing
%\renewenvironment{proof}
%{\textit{Proof.}~}
%{\hfill\rule{2mm}{2mm}\vspace{\parskip}}

\usepackage{algorithm}
\usepackage{algpseudocode}
\renewcommand{\thealgorithm}{\thedefinition}
%\newenvironment{Algorithm}
%{\begin{algorithm}[h]\stepcounter{definition}}
%{\end{algorithm}}
\let\oldalgorithm\algorithm
\let\oldendalgorithm\endalgorithm
\def\algorithm{\begingroup\oldalgorithm\stepcounter{definition}}
\def\endalgorithm{\oldendalgorithm\endgroup}
% (a hack)

\algblock{Class}{EndClass}
\algrenewtext{Class}{\textbf{class}}
\algrenewtext{EndWhile}{\textbf{end}}
\algrenewtext{EndFor}{\textbf{end}}
\algrenewtext{EndIf}{\textbf{end}}
\algrenewtext{EndFunction}{\textbf{end}}
\algrenewtext{EndClass}{\textbf{end}}

% Note: we're numbering all lemma's, definitions, examples, theorems, algorithms and such, TOGETHER (with the "definition" counter)

%\DeclareMathOperator*{\discup}{\dot\cup}
%
%\newcommand{\id}{\mathrm{id}}
%\newcommand{\DEF}{\buildrel\mathrm{def}\over{=}}
%\newcommand{\Iff}{~~\text{\normalfont iff}~~}
%
%\newcommand{\trans}[1]{\overset{#1}{\longrightarrow}}
%\newcommand{\Trans}[1]{\overset{#1}{\longsquiggly}}
%\newcommand{\TRANS}[2]{{\overset{#1}{\longsquiggly}}_{\!\!#2}\,\,}
%
%\newcommand{\Down}{{\downarrow}}
%\newcommand{\SN}{\ensuremath{\operatorname{SN}}}
%\newcommand{\SL}{\ensuremath{\operatorname{SL}}}
%\newcommand{\NL}{\ensuremath{\operatorname{NL}}}
%\newcommand{\opt}{\ensuremath{\operatorname{opt}}}
%
%\newcommand{\HK}{\text{HK}}
%\newcommand{\HKND}{\text{HK}\ensuremath{_\text{ND}}}


% DOCUMENT

\title{Compiling the Spla language}
\author{Kelley van Evert, s4046854}
%\date{}

\renewcommand{\syntleft}{\normalfont\itshape}
\renewcommand{\syntright}{}
% hack to get equal width
\def\synt#1{\mbox{\parbox{4.2cm}{\syntleft{#1\/}\syntright}}}%
\newcommand{\Alt}{\\%
  \mbox{\parbox{3.88cm}{~}\parbox{.4cm}{$|$}}}
%\def\alt{\\\llap{\textbar\quad}}%

\newcommand{\asmcomment}[1]{\normalfont\itshape// #1}
\newcommand{\asmpointer}[1]{\textbf{#1}}


\renewcommand{\ulitleft}{\ttfamily\bfseries%
%"
}
\renewcommand{\ulitright}{%
%"
}

\newcommand{\labelspace}{}


\newenvironment{asmcode}{%
\begin{tabular}{%
%@{~}!{\vrule width 1pt}
>{\ttfamily}l>{\ttfamily}l}%
}{%
\end{tabular}%
}

\newcommand{\fragment}[1]{{\normalfont\itshape$\langle$#1$\rangle$}}

\newcommand{\compile}[3]{{[\![ #3 ]\!]}^{#1}_{\text{\normalfont #2}}}

\newcommand{\asmlbl}[1]{{\normalfont\textit{\underline{#1}}}}

\newenvironment{Block}[1]{%
\begin{Warning}[singleextra={\path let \p1=(P), \p2=(O) in ($(\x2,0)+0.5*(0,\y1)$) node[mdframeleftlinetitle] {#1};}]%
}{%
\end{Warning}%
}

\begin{document}

\maketitle

%\vspace*{1.5em}
%\begin{abstract}
%Symbolic automata are a variation of normal automata designed to efficiently cope with large, potentially infinite alphabets. Existing NFA property checking methods need not apply to SFAs, due to their alternative definition. We demonstate how one can canonically transform symbolic automata to NFAs in such a manner that language acceptance is preserved, hence enabling the usage of existing language equivalence checking methods. We also study the essential efficient property of a symbolic automaton by means of providing a method for optimizing its alphabet, using a notion of minterms.
%\end{abstract}
%\vspace*{1em}

\setcounter{tocdepth}{2} % Sections & subsections only
\tableofcontents

\section{Introduction}

% what, scope
This paper describes the implementation of a compiler for the "Spla" language, in the context of a course on compiler construction given at the Radboud University Nijmegen. The Spla language was designed by the author as an extension of the "Splb" language used in earlier parts of the course, so as to allow it to compile itself.

% compiler
The compiler is written in Haskell and consist of a parser, built upon the notion of parser combinators, and a code generator, generating assembly for the "Simple Stack Machine" machine emulator by Atze Dijkstra. A type checker was available for the Splb language, implementing the well-known Algorithm W, but time constraints did not allow for its extension to Spla.


\section{The Spla language}

\subsection{Language overview}

The Spla language was designed by the author as an extension of the Splb language used in earlier parts of the course, adding \emph{whichever features were deemed neccessary or useful} so as to allow it to compile itself. Where Splb was a straight-forward C-like low-level imperative language, Spla now features the extensions and modifications:

\subsubsection*{New language constructs}

\begin{itemize}
\item \emph{Higher-order functions}, as values, allowing for the programming of constructs such as parser combinators, etc.
\item \emph{Nested function definitions}, where functions are expressed as values, allowing for easier programming.
\item \emph{Algebraic data types and pattern matching}, allowing for complex data structures and operations, typically useful for the definition and usage of abstract syntax trees, etc.
\item \emph{Type aliases}.
\item \emph{Strings}, though through the simple and inefficient hack of treating the string type as an alias for lists of integers, where each integer denotes the corresponding ASCII character.
\end{itemize}

\subsubsection*{Semantic differences from Splb}

\begin{itemize}
\item Equality is now structural equality, where Splb treated list/tuple equality by-reference.
\end{itemize}

\subsubsection*{Oddities}

As such the language has become a weird, and frankly somewhat uninformed, hybrid of the functional en imperative paradigms. The following key points explain this:

\begin{itemize}
\item Strict evaluation, allowing for stately imperative programs to be written.
\item Aggregate data types (lists, tuples, and algebraic data types) are passed by reference, though equality is checked structurally.
\item Functions are expressed and passed around as values, allowing for complex functional programs to be written, though partial function application is not allowed.
\end{itemize}

\subsection{Safety}

Spla is type-safe, and the only dynamic exception that can occur is that of accessing head or tail segments of empty lists.


\subsection{Formal specification}

The following ENBF-inspired grammar specifies syntactically valid Spla programs. Spla syntax is written in bold monotype, and regular expressions are used for convenience.

%\newcommand{\nonterm}[2]{#1 & $#2$}
%\newcommand{\alt}{$|$}
%\begin{tabular}{@{}lll@{}}
%\nonterm{Unary operator}{-} \texttt{"!"} \alt \texttt{"-"}
%\end{tabular}

\begin{Block}{Formal grammar of Spla}

\begin{grammar}

<Unary operator \hfill $\&$> ::= "!" | "-"

<Binary operator \hfill $\otimes$> ::= "+" | "-" | "*" | "/" | "%"
| "==" | "!="
| ">=" | "<=" | ">" | "<"
| "&&" | "||"

<Integer \hfill $n$> ::= ["0"-"9"]$^+$

<Boolean \hfill $b$> ::= "true" | "false"

<Identifier \hfill $x,y$> ::= ["a"-"z"]["_""a"-"z""0"-"9""'"]*

<Constructor \hfill $c$> ::= ["A"-"Z"]["_""a"-"z""0"-"9""'"]*

<Type \hfill $\tau$> ::= "'"$x$ | "unit" | "bool" | "int" | "[" $\tau$ "]" | "(" $\tau$ "," $\tau$ ")" | $\tau$ "->" $\tau$
\Alt $c$ | $c$ "(" $\tau$ ("," $\tau$)* ")"

<Polymorphic type \hfill $\sigma$> ::= $\tau$ | "forall" $x$ (\textvisiblespace\,$x$)*"." $\sigma$

<Literal \hfill $\ell$> ::= $b$ | $n$ | "[]" | "()"

<Expression \hfill $E$> ::= $a$ | $d$ | $f$ | $\ell$ | $E \otimes E$ | $\&E$
\Alt $E$ ":" $E$
\Alt "(" $E$ "," $E$ ")"
\Alt "(" $E$ ")"
\Alt "fun (" ($x$ ("," $x$)$^*$)? ")" $B$
\Alt "let" $x$ "=" $E$ "in" $E$
\hfill \emph{included for Hindley-Milner typing}
\Alt "match" $E$ "{" $R_\textit{Expr}$* "}"

<Match rule \hfill $R_\textit{Expr}$> ::= "|" $E_\textit{Pattern}$ "->" $E$

<Pattern \hfill $E_\textit{Pattern}$> ::= $x$ | $d$ | $\ell$
\Alt $E$ ":" $E$
\Alt "(" $E$ "," $E$ ")"
\Alt "(" $E$ ")"

<Function call \hfill $f$> ::= $x$ "(" ($E$ ("," $E$)*)? ")"

<Data \hfill $d$> ::= $c$ | $c$ "(" $E$ ("," $E$)* ")"

<Field \hfill $h$> ::= "hd" | "tl" | "fst" | "snd"

<Access \hfill $a$> ::= $x$ ["." $h$]*

<Block \hfill $B$> ::= "{" $S$* "}"

<Statement \hfill $S$> ::= "skip;"
            \Alt "if" "(" $E$ ")" $B$ ("else" $B$)?
            \Alt "while" "(" $E$ ")" $B$
            \Alt $a$ "=" $E$ ";"
            \Alt $f$ ";"
            \Alt "return" $E$? ";"
            \Alt B
            \Alt "let" $x$ "=" $S$ "in" $S$
            \hfill \emph{included for Hindley-Milner typing}
            \Alt "match" $E$ "{" $R_\textit{Stmt}$* "}"

<Match rule \hfill $R_\textit{Stmt}$> ::= "|" $E_\textit{Pattern}$ "->" $S$

<Program \hfill $P$> ::= $F$*
\end{grammar}

\end{Block}

Semantically valid Spla programs are those that are syntactically valid, satisfy certain static criteria, see Subsection \ref{staticcheck}, and are found valid by the type system expounded in Subsection \ref{typesystem}.


\section{Notation, terminology and conventions}

\subsection{Abstract concrete grammar}

Although the above specified grammar of Spla is its concrete grammar, we will use it throughout this paper as its abstract syntax tree as well, to facilitate reading, taking into account the following points:

\begin{itemize}

\item We omit a few right-hand side clauses from the abstract syntax tree, by performing the rewriting rules listed below, where $x_\textrm{\normalfont fresh}$ stands for some freshly chosen identifier.
\begin{align*}
\lit*{($E$)} &\xmapsto{\phantom{....}} E \\
\lit*{if ($E$) then $B$} &\xmapsto{\phantom{....}} \lit*{if ($E$) then $B$ else \{ skip; \}} \\
\lit*{return;} &\xmapsto{\phantom{....}} \lit*{return ();} \\
\lit*{$\tau$ $x$ () $B$} &\xmapsto{\phantom{....}} \lit*{$\tau$ $x$ (unit $x_\textrm{\normalfont fresh}$) $B$} \\
\lit*{$c$} &\xmapsto{\phantom{....}} \lit*{$c$()}
%\\ \lit*{$\tau$} &\xmapsto{\phantom{....}} \lit*{forall $x_1 \dots x_n$. $\tau$}\quad\textit{where~~}\textrm{fv}(\tau) = \{x_1 \dots x_n\}
%\\ \lit*{forall $\overline{x}$. forall $\overline{y}$. $\sigma$} &\xmapsto{\phantom{....}} \lit*{forall $\overline{x}$ $\overline{y}$. $\sigma$}
\end{align*}

\item When accounting for some piece of abstract syntax containing a sequence of similar segments, we sometimes tacitly omit separating or intermediate syntax, as in the following examples:
\begin{align*}
\lit*{$\tau$ $x$ ($\tau_1$ $x_1$, $\tau_2$ $x_2$, $\tau_3$ $x_3$, $\tau_4$ $x_4$) $B$} &\textrm{~~e.g. written as~~} \lit*{$\tau$ $x$ ($\tau_1$ $x_1$, $\dots \tau_4$ $x_4$) $B$} \\
\lit*{$x$($E_1$, $E_2$, $E_3$, $E_4$) $B$} &\textrm{~~e.g. written as~~} \lit*{$x$($E_1 \dots E_4$)} \\
\lit*{\{$\tau_1$ $x_1$; $\tau_2$ $x_2$; $\tau_3$ $x_3$; $S_1$ $S_2$ $S_3$\}} &\textrm{~~e.g. written as~~} \lit*{\{$\tau_1$ $x_1$; $\dots \tau_3$ $x_3$; $\overline{S}$\}}
\end{align*}

\item Field access dot notation is left associative, e.g. \lit*{$x$.$d_1$.$d_2$.$d_3$} stands for \lit*{$(((x$.$d_1)$.$d_2)$.$d_3)$}.

\item Usual binding powers apply to binary and unary operations in expressions.

\end{itemize}


\subsection{Assembly signatures}

We denote the effect of arbitrary pieces of assembly code on the stack by assigning it an \emph{assembly signature}. An assembly signature has the shape \lit*{$n$ -> $m$}, and means that the given bit a assembly uses the top $n$ elements of the stack as arguments, and results in the new top $m$ elements of the stack. (The stack size now being positively changed by $m-n$.) If $A$ is a piece of assembly, we write \lit*{$A$ :: $n$ -> $m$}.


\subsection{Terminology}

\begin{description}
\item[Access (variable)] An access variable is the \emph{normal} kind of variable used in Spla code, and \emph{access} stands for the act of accessing a value it implies. It is mainly terminology used to contrast with the notion of a \emph{capturing variable}.
\item[Capturing variable] A capturing variable is a variable in a match pattern (expression), which therefore is not an access variable, but declares a (captured) local in the lexical scope of its match rule if the match rule applies.
\item[Lexical scope/context] A lexical scope is a textual range in Spla code in which a variable lives. A lexical context is an execution environment in which variables of a lexical scope are assigned values.
\end{description}


\section{Semantics}


\subsection{Lexical scoping}

Spla features lexical scoping through the following language constructs:
\begin{itemize}
\item global scope;
\item let construct;
\item block;
\item function body;
\item match rule;
\end{itemize}

Function an variable shadowing is allowed, but constructor shadowing is not. Variables are visible everywhere in their declaring lexical scope, though may not be accessed until declared.

It must be noted that the notion of a \emph{lexical context} is different than that of a \emph{lexical scope}. A lexical scope is a textual range in Spla code in which a variable lives. A lexical context is an execution environment in which variables of a lexical scope are assigned values. Lexical contexts are created at runtime whenever execution enters a lexical scope or a function is called.


\subsection{Static check}
\label{staticcheck}

Aside from being well-typed, a syntactically valid program must first satisfy the following (statically checkable) criteria to be found a valid Spla program. Parenthesized items are not criteria, but remarks.


\subsubsection*{Type declarations}

A declared type is either a type alias or an ADT.

\begin{itemize}
\item (Order of type declarations does not matter.)
\item Type aliases declarations may not be circular.
\item All constructors must have different names.
\item All declared types must have different names.
\item Declared types must not have free type variables (that is, free type variables must be captured as type arguments to the declared type).
\item A constructor can be used as a function, but otherwise a data expression must have the right amount of arguments, i.e. partial application does not exist.
\end{itemize}


\subsubsection*{Lexical issues}

\begin{itemize}
\item All variables declared in a lexical scope must have different names.
\item (Shadowing variables or functions in outer lexical scopes is allowed.)
\item Shadowing constructors is not allowed.
\item In a given lexical scope, access to a variable may only occur \emph{after} its declaration. This also means that if the variable is not yet declared, but another variable with the same name is defined in an outer scope, the access does not reach out to the other variable, but is invalid.
\end{itemize}


\subsubsection*{Match construct}

\begin{itemize}
\item An expression match must cover all cases. (Whereas a statement match need not.)
\item (As each match rule defines a new lexical scope, and capturing variables are not access variables but define locals in this lexical scope, they must all have different names.)
\end{itemize}


\subsubsection*{Returning}

\begin{itemize}
\item Each function must have a returning statement. A returning statement is a return statement, or a statement that always returns. E.g., an if statement always returns iff both branches always return, etc.
\end{itemize}


\subsubsection*{Miscellaneous}

\begin{itemize}
\item Each program must contain a function \lit*{main} of type \lit*{unit -> int}.
\end{itemize}


\subsection{Dynamic exceptions}

Note that above stated criteria do not guarantee dynamic safety. The only dynamic exception that can occur in Spla is that of access or storage of \lit*{hd} or \lit*{tl} segments of empty lists. Program will then jump to the \lit*{_EXCEPTION_EmptyList} label and halt.

Moreover, heap storage is as of yet not garbage collected.


\subsection{Typing system}
\label{typesystem}

Spla features a Hindley-Milner polymorphic type system. The possible function types are those admitted by the grammar as a \textit{(Polynorphic type)} of the form $\sigma = \lit*{forall $\dots$. $\tau_1$ -> $\tau_2$}$. These are not included in the concrete grammar of Spla, instead they are implicitly generalized as in, for example, Haskell. This means that a function $x$, concretely defined as
\begin{equation*}
\lit*{$\tau_{n+1}$ $x$ ($\tau_1$ $x_1$, $\dots \tau_n$ $x_n$) $B$}
\end{equation*}
is implicitly regarded as having the $\lambda 2$ type signature
\begin{equation*}
x : \lit*{forall $y_1 \dots y_k$. $\tau_1$ -> $\dots$ -> $\tau_n$ -> $\tau_{n+1}$}
\end{equation*}
where
\begin{equation*}
\bigcup_{j=1}^{n+1}\,\textrm{fv}(\tau_j) = \{y_1 \dots y_k\}\textrm{.}
\end{equation*}

The type system of Spla is pretty much exactly the same as that of Splb. As we have not yet completed its implementation, we haven't included any specifics of it in this document. Refer to the Splb document for the general idea.



\section{Implementation notes}


\subsection{Code infrastructure}

Code is divided into groups of modules as follows.
\begin{description}
\item[Language]\hfill
  \begin{description}
  \item[\lit*{Spla.Language}] Describes language in terms of syntax fragments, AST, operators, lexing tokens, type theory, and basic as well as general operations on these data.
  \end{description}
\item[Parser]\hfill
  \begin{description}
  \item[\lit*{ParserCombinators}] A basic parser combinator library.
  \item[\lit*{Spla.Lexer}] Defines \lit*{splalex :: String -> [Tokens]}.
  \item[\lit*{Spla.Parser}] Defines \lit*{splaparse :: [Tokens] -> Program}.
  \end{description}
\item[Static analysis]\hfill
  \begin{description}
  \item[\lit*{Spla.TypeCheck}] Defines the function \lit*{staticCheck :: Program -> Program}, which enforces static semantic criteria on syntactically valid Spla programs, as well as the function \lit*{typecheck :: Program -> Program}, which does actual type checking (and inferring). Note that this module is not completed, due to time constraints, but can, in principle, be easily extended from the static analysis module of Spla.
  \end{description}
\item[Code generation]\hfill
  \begin{description}
  \item[\lit*{Spla.SSMCompile}] Defines \lit*{compileP :: Program -> Asm}.
  \end{description}
\end{description}

All groups depend on the language group, through for the rest they are fully independent.

\subsection{Coding patterns}

\subsubsection{Traits}

The AST is defined with ADTs such as \lit*{Program}, \lit*{Stmt} and \lit*{Expr}. As the AST is often traversed to perform a specific action, such as compiling or checking for free variables, we have often used what we call the "trait" pattern, where a Haskell class defines a specific trait (compileable, having lexical meaning, etc), and applicable ADTs implement this class. As such we have, for example, the following traits:

\begin{itemize}
\item To deal with compilation (implemented by \lit*{Program}, \lit*{Stmt}, \lit*{Expr}, \lit*{Let}, \lit*{Match} and \lit*{Lit})
  \begin{minted}{haskell}
  class Compileable a where
    compile :: String -> a -> Compiler Asm
  \end{minted}
\item To deal with lexical issues (implemented by \lit*{Access}, \lit*{Stmt}, \lit*{Expr}, \lit*{Let}, \lit*{Match}, \lit*{MatchRule} and \lit*{FunCall})
  \begin{minted}{haskell}
  class LexicalVars a where
    fv :: a -> Set String
    subst :: Subst -> a -> a
  \end{minted}
\end{itemize}

\subsubsection{Alternative compilation schemes}

Instead of defining a separate ADT, we decided to use the normal expression ADT to represent match pattern expressions. This approach avoids a lot of (messy) code duplication in the compiler (which we would have had by defining a new ADT, or boxing), but also introduces an obvious problem with regard to the "trait" approach explained above. Therefore we adopted an approach in which we pass a flag to the \lit*{compile} function indicating what alternative compilation scheme should be used. For example, the expression ADT has three different compilation schemes:
\begin{description}
\item[Normal] Compiles expressions as values, as usual.
\item[Match pattern expression] Allows compiling match wildcards (\lit*{_}) as well, and doesn't compile identifiers (as they are now to be regarded as capture variables instead of access variables).
\item[Match check expression] Regards given expression as a match pattern expression. Instead of compiling to assembly producing a single element on the heap, it compiles to assembly that compares the top two elements on the heap via its input, capturing expressions in the current match rule lexical context when encountering capture variables, and producing a boolean answer on the stack.
\end{description}

As an illustration of this approach, here is an outline of the implementation of the \lit*{Compileable} trait by the \lit*{Expr} ADT:
\begin{minted}{haskell}
instance Compileable Expr where
  -- don't compile as access variable, instead just load dummy value
  compile "match_expr" (E_Access (Ident id))
  -- allow this compilation, just load dummy value
  compile "match_expr" (E_MatchWildcard)

  compile "match_check" (E_MatchWildcard) -- always true
  compile "match_check" (E_Lit l)
  compile "match_check" (E_Data (Data cName args))
  compile "match_check" (E_Tuple e1 e2)
  compile "match_check" (E_BinOp ":" e1 e2)
  compile "match_check" (E_Access (Ident x)) -- capture

  -- normal expression compilation...
\end{minted}



%\cleardoublepage
%\phantomsection
%\addcontentsline{toc}{section}{References}
%\nocite{*}
%\raggedright
%\bibliographystyle{plainnat}
%\bibliography{status1}{}


\end{document}
